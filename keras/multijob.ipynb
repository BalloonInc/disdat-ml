{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "import balloonml\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config ={}\n",
    "\n",
    "config['output']='disdat-104-v1'\n",
    "\n",
    "config['train_data_dir'] = '../clean-data'\n",
    "config['validation_data_dir'] = '../clean-validation'\n",
    "\n",
    "config['bottleneck_train'] = 'bottleneck_features_train.npy'\n",
    "config['bottleneck_validation'] = 'bottleneck_features_validation.npy'\n",
    "\n",
    "# True if bottleneck features are not available yet, \n",
    "# False if they are and can be lodaded\n",
    "calculate_bottleneck = True \n",
    "\n",
    "config['epochs'] = 25\n",
    "config['epochs-refine'] = 10\n",
    "\n",
    "config['batch_size'] = 32\n",
    "\n",
    "config['optimizer']='sgd'\n",
    "config['lr']=0.002\n",
    "config['decay']=1/100 * (config['lr'])/(100000/config['batch_size'])\n",
    "\n",
    "with open(config['output']+'.config', 'w') as fp:\n",
    "    json.dump(config, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving or loading bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 115042 images belonging to 104 classes.\n"
     ]
    }
   ],
   "source": [
    "if calculate_bottleneck:\n",
    "    model = VGG16(include_top=False, weights='imagenet')\n",
    "    train_data = balloonml.bottleneck(model,config['train_data_dir'],config['bottleneck_train'], config['batch_size'])\n",
    "    validation_data = balloonml.bottleneck(model,config['validation_data_dir'],config['bottleneck_validation'], config['batch_size'])\n",
    "else:\n",
    "    train_data = np.load(config['bottleneck_train'])\n",
    "    validation_data = np.load(config['bottleneck_validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if config['optimizer']=='sgd':\n",
    "    optimizer=SGD(lr=config['lr'], decay=config['decay'])\n",
    "elif config['optimizer']=='rmsprop':\n",
    "    optimizer=RMSprop(lr=config['lr'], decay=config['decay'])\n",
    "\n",
    "history, model = balloonml.train_top(\n",
    "    train_data, \n",
    "    validation_data,\n",
    "    train_data_dir=config['train_data_dir'], \n",
    "    validation_data_dir=config['validation_data_dir'],\n",
    "    optimizer=optimizer,\n",
    "    batch_size = config['batch_size'],\n",
    "    epochs=config['epochs'],\n",
    "    output=config['output'])\n",
    "balloonml.plotResult(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "refine_optimizer=SGD(lr=1e-4, momentum=0.9)\n",
    "\n",
    "refined_history, refined_model = balloonml.finetune(\n",
    "    train_data_dir=config['train_data_dir'],\n",
    "    validation_data_dir=config['validation_data_dir'], \n",
    "    optimizer=refine_optimizer, \n",
    "    weights_top_layer=config['output']+'.h5', \n",
    "    batch_size=config['batch_size'], \n",
    "    epochs=config['epochs-refine'],\n",
    "    output=config['output']+'-refined')\n",
    "balloonml.plotResult(refined_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "img_width, img_height = 224, 224\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "import keras.callbacks\n",
    "\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "\n",
    "datagen_top = ImageDataGenerator(rescale=1. / 255)\n",
    "generator_training_top = datagen_top.flow_from_directory(\n",
    "    config['train_data_dir'],\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=config['batch_size'],\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "num_classes = len(generator_training_top.class_indices)\n",
    "\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(config['output']+'.h5')\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        config['train_data_dir'],\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=config['batch_size'],\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        config['validation_data_dir'],\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=config['batch_size'],\n",
    "        class_mode='categorical')\n",
    "\n",
    "nb_train_samples = len(train_generator.filenames)\n",
    "\n",
    "nb_validation_samples = len(validation_generator.filenames)\n",
    "\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./logs/'+config['output']+'-refine', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "# fine-tune the model\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // config['batch_size'],\n",
    "        epochs=config['epochs-refine'],\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // config['batch_size'],\n",
    "        callbacks=[tbCallBack])\n",
    "\n",
    "model.save_weights(config['output']+\"-refined.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coreml_model  = coremltools.converters.keras.convert(model,\n",
    "                                                    image_input_names='image',\n",
    "                                                    class_labels='labels.txt',\n",
    "                                                    input_names=['image'],  \n",
    "                                                    red_bias=-123.68,\n",
    "                                                    green_bias=-116.78,\n",
    "                                                    blue_bias=-103.94\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coreml_model.save(config['output']+\"-refined.mlmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the class_indices saved in the earlier step\n",
    "class_dictionary = np.load('class_indices.npy').item()\n",
    "\n",
    "num_classes = len(class_dictionary)\n",
    "\n",
    "# add the path to your test image below\n",
    "\n",
    "orig = cv2.imread('test_images/keyboard.jpg')\n",
    "\n",
    "print(\"[INFO] loading and preprocessing image...\")\n",
    "image = load_img(image_path, target_size=(224, 224))\n",
    "image = img_to_array(image)\n",
    "\n",
    "# important! otherwise the predictions will be '0'\n",
    "image = image / 255\n",
    "\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "class_predicted = model.predict_classes(image)\n",
    "\n",
    "probabilities = model.predict_proba(image)\n",
    "print(probabilities)\n",
    "inID = class_predicted[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "\n",
    "datagen_top = ImageDataGenerator(rescale=1. / 255)\n",
    "generator_training_top = datagen_top.flow_from_directory(\n",
    "    config['train_data_dir'],\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=config['batch_size'],\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "num_classes = len(generator_training_top.class_indices)\n",
    "\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "#top_model.load_weights(config['output']+'.h5')\n",
    "\n",
    "top_model.load_weights(config['output']+'.h5')\n",
    "\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(config['output']+'-refined.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_path = 'test_images/keyboard.jpg'\n",
    "img=mpimg.imread(image_path)\n",
    "plt.imshow(img)\n",
    "print(\"I think this is a \"+balloonml.predict(image_path, config['output']+\"-refined.h5\")+\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orig = cv2.imread('test_images/keyboard.jpg')\n",
    "\n",
    "print(\"[INFO] loading and preprocessing image...\")\n",
    "image = load_img('test_images/keyboard.jpg', target_size=(224, 224))\n",
    "image = img_to_array(image)\n",
    "\n",
    "# important! otherwise the predictions will be '0'\n",
    "image = image / 255\n",
    "\n",
    "image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probabilities = model.predict(image)\n",
    "print(classes)\n",
    "print(probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
