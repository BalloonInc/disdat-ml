{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import operator\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.callbacks\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import coremltools\n",
    "\n",
    "from PIL import Image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = 'disdat-120-v1-softmax-lr0.001-decay0'\n",
    "label_file='labels.txt'\n",
    "data_folder='../data'\n",
    "output='disdatkerasv8'\n",
    "num_classes=120\n",
    "\n",
    "write_labels=True\n",
    "load_only=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape=(7,7,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 137623 images belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "if write_labels:\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    data_generator = datagen.flow_from_directory(\n",
    "        data_folder,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=11,\n",
    "        class_mode='sparse'\n",
    "    )\n",
    "\n",
    "    class_dictionary = data_generator.class_indices\n",
    "\n",
    "    sorted_predictions = sorted(class_dictionary.items(), key=operator.itemgetter(1))\n",
    "    labels=[p[0] for p in sorted_predictions]\n",
    "\n",
    "    with open(label_file, 'w') as f:\n",
    "        for label in labels:\n",
    "            f.write(label+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(weights+'.config') as config_file:    \n",
    "    config=json.load(config_file)\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(num_classes, activation='softmax'))\n",
    "decay=1/100 * (config['lr'])/(100000/config['batch_size'])\n",
    "top_model.compile(optimizer=SGD(lr=config['lr'], decay=config['decay']),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "top_model.load_weights(weights+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs= base_model.input, outputs= top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : input_2, <keras.engine.topology.InputLayer object at 0x11ed18c10>\n",
      "1 : block1_conv1, <keras.layers.convolutional.Conv2D object at 0x111297050>\n",
      "2 : block1_conv1__activation__, <keras.layers.core.Activation object at 0x124003610>\n",
      "3 : block1_conv2, <keras.layers.convolutional.Conv2D object at 0x11978cb10>\n",
      "4 : block1_conv2__activation__, <keras.layers.core.Activation object at 0x124010b50>\n",
      "5 : block1_pool, <keras.layers.pooling.MaxPooling2D object at 0x12287c8d0>\n",
      "6 : block2_conv1, <keras.layers.convolutional.Conv2D object at 0x111297090>\n",
      "7 : block2_conv1__activation__, <keras.layers.core.Activation object at 0x124010cd0>\n",
      "8 : block2_conv2, <keras.layers.convolutional.Conv2D object at 0x12289e650>\n",
      "9 : block2_conv2__activation__, <keras.layers.core.Activation object at 0x124010c90>\n",
      "10 : block2_pool, <keras.layers.pooling.MaxPooling2D object at 0x122aaea10>\n",
      "11 : block3_conv1, <keras.layers.convolutional.Conv2D object at 0x1229fde90>\n",
      "12 : block3_conv1__activation__, <keras.layers.core.Activation object at 0x124010d50>\n",
      "13 : block3_conv2, <keras.layers.convolutional.Conv2D object at 0x122a38dd0>\n",
      "14 : block3_conv2__activation__, <keras.layers.core.Activation object at 0x124010dd0>\n",
      "15 : block3_conv3, <keras.layers.convolutional.Conv2D object at 0x122a5fcd0>\n",
      "16 : block3_conv3__activation__, <keras.layers.core.Activation object at 0x124010e50>\n",
      "17 : block3_pool, <keras.layers.pooling.MaxPooling2D object at 0x122abca10>\n",
      "18 : block4_conv1, <keras.layers.convolutional.Conv2D object at 0x122ac9cd0>\n",
      "19 : block4_conv1__activation__, <keras.layers.core.Activation object at 0x124010ed0>\n",
      "20 : block4_conv2, <keras.layers.convolutional.Conv2D object at 0x122b3e9d0>\n",
      "21 : block4_conv2__activation__, <keras.layers.core.Activation object at 0x124010f50>\n",
      "22 : block4_conv3, <keras.layers.convolutional.Conv2D object at 0x122b20d10>\n",
      "23 : block4_conv3__activation__, <keras.layers.core.Activation object at 0x124010fd0>\n",
      "24 : block4_pool, <keras.layers.pooling.MaxPooling2D object at 0x122b89d90>\n",
      "25 : block5_conv1, <keras.layers.convolutional.Conv2D object at 0x122bb7990>\n",
      "26 : block5_conv1__activation__, <keras.layers.core.Activation object at 0x12401f090>\n",
      "27 : block5_conv2, <keras.layers.convolutional.Conv2D object at 0x122c0d9d0>\n",
      "28 : block5_conv2__activation__, <keras.layers.core.Activation object at 0x12401f110>\n",
      "29 : block5_conv3, <keras.layers.convolutional.Conv2D object at 0x122b967d0>\n",
      "30 : block5_conv3__activation__, <keras.layers.core.Activation object at 0x12401f190>\n",
      "31 : block5_pool, <keras.layers.pooling.MaxPooling2D object at 0x122cbbb90>\n",
      "32 : sequential_2_flatten_2, <keras.layers.core.Flatten object at 0x11f06cd90>\n",
      "33 : sequential_2_dense_3, <keras.layers.core.Dense object at 0x11b4f30d0>\n",
      "34 : sequential_2_dense_3__activation__, <keras.layers.core.Activation object at 0x12401f1d0>\n",
      "35 : sequential_2_dense_4, <keras.layers.core.Dense object at 0x12307c090>\n",
      "36 : sequential_2_dense_4__activation__, <keras.layers.core.Activation object at 0x12401f210>\n"
     ]
    }
   ],
   "source": [
    "if load_only:\n",
    "    coreml_model = coremltools.models.MLModel(output+'top.mlmodel')\n",
    "else:\n",
    "    coreml_model  = coremltools.converters.keras.convert(model,\n",
    "                                                        image_input_names='image',\n",
    "                                                        class_labels=label_file,\n",
    "                                                        input_names=['image'],  \n",
    "    #                                                     red_bias=-123.682/255,\n",
    "    #                                                     green_bias=-116.78/255,\n",
    "    #                                                     blue_bias=-103.94/255,\n",
    "                                                        image_scale=1/255.0\n",
    "    )\n",
    "    \n",
    "# Set model metadata\n",
    "coreml_model.author = 'Balloon Inc. VOF'\n",
    "coreml_model.short_description = 'Custom object detection for 120 simple classes.'\n",
    "\n",
    "\n",
    "coreml_model.save(output+'top.mlmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "refined_model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "\n",
    "refined_model.load_weights(weights+'-refined.h5')\n",
    "refined_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=2e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if load_only:\n",
    "    coreml_model_refined = coremltools.models.MLModel(output+'.mlmodel')\n",
    "else:\n",
    "    coreml_model_refined  = coremltools.converters.keras.convert(refined_model,\n",
    "                                                        image_input_names='image',\n",
    "                                                        class_labels=label_file,\n",
    "                                                        input_names=['image'],  \n",
    "    #                                                     red_bias=-123.68/255,\n",
    "    #                                                     green_bias=-116.78/255,\n",
    "    #                                                     blue_bias=-103.94/255,\n",
    "                                                        image_scale=1/255.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set model metadata\n",
    "coreml_model_refined.author = 'Balloon Inc. VOF'\n",
    "coreml_model_refined.short_description = 'Custom object detection for 120 simple classes.'\n",
    "\n",
    "coreml_model_refined.save(output+'-refined.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import balloonml\n",
    "\n",
    "img_path='test_images/'\n",
    "images = ['calculator.jpg',\n",
    "'dog.jpg',\n",
    "'cat.jpg',\n",
    "'keyboard.jpg',\n",
    "'macbook.jpg',\n",
    "'mouse.jpg',\n",
    "'banana.jpg']\n",
    "for image in images:\n",
    "    print('Predicting '+image)\n",
    "    path = img_path+image\n",
    "    # keras prediction\n",
    "    print(balloonml.predict_top(path, weights+'.h5',class_dictionary))\n",
    "    print(balloonml.predict_fine(model,class_dictionary, img_path=path))\n",
    "    \n",
    "    # CoreML prediction\n",
    "    im = Image.open(path)  \n",
    "    coreml_model.predict({'data': im})  \n",
    "    coreml_model_refined.predict({'data': im})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test images for v5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting calculator.jpg\n",
    "1/1 [==============================] - 0s\n",
    "1/1 [==============================] - 0s\n",
    "[('calculator', 0.021121915), ('keyboard', 0.00038548166), ('key', 6.198656e-05), ('hairbrush', 5.6152505e-05)]\n",
    "[('calculator', 0.2597464), ('keyboard', 0.00038322349), ('key', 9.7186203e-06), ('computer mouse', 2.592287e-06)]\n",
    "Predicting dog.jpg\n",
    "1/1 [==============================] - 0s\n",
    "1/1 [==============================] - 0s\n",
    "[('cat', 0.0047040172), ('dog', 0.0040679271), ('sofa', 0.00085722323), ('dinosaur', 0.00027150256)]\n",
    "[('cat', 0.0052334545), ('dog', 0.0040698401), ('dinosaur', 0.00085430447), ('sofa', 0.00056111149)]\n",
    "Predicting cat.jpg\n",
    "1/1 [==============================] - 0s\n",
    "1/1 [==============================] - 0s\n",
    "[('cat', 0.29206869), ('dog', 0.0055200113), ('star', 5.3297485e-05), ('dinosaur', 3.7203841e-05)]\n",
    "[('cat', 0.35923439), ('dog', 0.00079333514), ('star', 2.7750855e-05), ('dinosaur', 1.5055543e-05)]\n",
    "Predicting keyboard.jpg\n",
    "1/1 [==============================] - 0s\n",
    "1/1 [==============================] - 0s\n",
    "[('radiator', 0.0022044962), ('curtain', 0.00061480148), ('ruler', 0.0005549785), ('blackboard', 0.00050748681)]\n",
    "[('ruler', 0.0010941911), ('keyboard', 0.00091195788), ('computer mouse', 0.00040513425), ('guitar', 0.00040082214)]\n",
    "Predicting macbook.jpg\n",
    "1/1 [==============================] - 0s\n",
    "1/1 [==============================] - 0s\n",
    "[('keyboard', 0.01001082), ('monitor', 0.00050369196), ('blackboard', 0.00025121815), ('computer mouse', 0.00018567205)]\n",
    "[('keyboard', 0.047883309), ('monitor', 0.00047867949), ('computer mouse', 0.00031897088), ('calculator', 0.00015937244)]\n",
    "Predicting mouse.jpg\n",
    "1/1 [==============================] - 0s\n",
    "1/1 [==============================] - 0s\n",
    "[('soap', 0.0042663808), ('computer mouse', 0.00091027975), ('bowl', 0.00067775662), ('pan', 0.00041909842)]\n",
    "[('soap', 0.0056782723), ('computer mouse', 0.0010733134), ('bowl', 0.00028223582), ('hat', 0.00015233312)]\n",
    "Predicting banana.jpg\n",
    "1/1 [==============================] - 0s\n",
    "1/1 [==============================] - 0s\n",
    "[('banana', 0.012315591), ('bowl', 0.00019367522), ('sock', 0.00017960947), ('carrot', 5.7873309e-05)]\n",
    "[('banana', 0.043339983), ('bowl', 0.00051319768), ('onion', 0.00012041288), ('soap', 0.00011019995)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
