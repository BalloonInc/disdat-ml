{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:root:Keras version 2.0.6 detected. Last version known to be fully compatible of Keras is 2.0.4 .\n",
      "WARNING:root:TensorFlow version 1.3.0-rc2 detected. Last version known to be fully compatible is 1.1.1 .\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.callbacks\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape=(7,7,512)\n",
    "num_classes=84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.load_weights('multiclass_50epochs_sgd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs= base_model.input, outputs= model(base_model.output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : input_1, <keras.engine.topology.InputLayer object at 0x104119e10>\n",
      "1 : block1_conv1, <keras.layers.convolutional.Conv2D object at 0x104119a50>\n",
      "2 : block1_conv1__activation__, <keras.layers.core.Activation object at 0x115249e50>\n",
      "3 : block1_conv2, <keras.layers.convolutional.Conv2D object at 0x104119ed0>\n",
      "4 : block1_conv2__activation__, <keras.layers.core.Activation object at 0x116b5ad50>\n",
      "5 : block1_pool, <keras.layers.pooling.MaxPooling2D object at 0x111444c10>\n",
      "6 : block2_conv1, <keras.layers.convolutional.Conv2D object at 0x11148f1d0>\n",
      "7 : block2_conv1__activation__, <keras.layers.core.Activation object at 0x116b5ad90>\n",
      "8 : block2_conv2, <keras.layers.convolutional.Conv2D object at 0x111480190>\n",
      "9 : block2_conv2__activation__, <keras.layers.core.Activation object at 0x116b5aed0>\n",
      "10 : block2_pool, <keras.layers.pooling.MaxPooling2D object at 0x11149d710>\n",
      "11 : block3_conv1, <keras.layers.convolutional.Conv2D object at 0x1114dc510>\n",
      "12 : block3_conv1__activation__, <keras.layers.core.Activation object at 0x116b5af50>\n",
      "13 : block3_conv2, <keras.layers.convolutional.Conv2D object at 0x11150d110>\n",
      "14 : block3_conv2__activation__, <keras.layers.core.Activation object at 0x116b5afd0>\n",
      "15 : block3_conv3, <keras.layers.convolutional.Conv2D object at 0x11154b690>\n",
      "16 : block3_conv3__activation__, <keras.layers.core.Activation object at 0x116b65090>\n",
      "17 : block3_pool, <keras.layers.pooling.MaxPooling2D object at 0x1115a9110>\n",
      "18 : block4_conv1, <keras.layers.convolutional.Conv2D object at 0x111599d90>\n",
      "19 : block4_conv1__activation__, <keras.layers.core.Activation object at 0x116b65110>\n",
      "20 : block4_conv2, <keras.layers.convolutional.Conv2D object at 0x11158db10>\n",
      "21 : block4_conv2__activation__, <keras.layers.core.Activation object at 0x116b65190>\n",
      "22 : block4_conv3, <keras.layers.convolutional.Conv2D object at 0x1116261d0>\n",
      "23 : block4_conv3__activation__, <keras.layers.core.Activation object at 0x116b65210>\n",
      "24 : block4_pool, <keras.layers.pooling.MaxPooling2D object at 0x111667750>\n",
      "25 : block5_conv1, <keras.layers.convolutional.Conv2D object at 0x1116585d0>\n",
      "26 : block5_conv1__activation__, <keras.layers.core.Activation object at 0x116b65290>\n",
      "27 : block5_conv2, <keras.layers.convolutional.Conv2D object at 0x1116970d0>\n",
      "28 : block5_conv2__activation__, <keras.layers.core.Activation object at 0x116b65310>\n",
      "29 : block5_conv3, <keras.layers.convolutional.Conv2D object at 0x1116b5710>\n",
      "30 : block5_conv3__activation__, <keras.layers.core.Activation object at 0x116b65390>\n",
      "31 : block5_pool, <keras.layers.pooling.MaxPooling2D object at 0x111732f10>\n",
      "32 : sequential_1_flatten_1, <keras.layers.core.Flatten object at 0x114fbfbd0>\n",
      "33 : sequential_1_dense_1, <keras.layers.core.Dense object at 0x114fbff90>\n",
      "34 : sequential_1_dense_1__activation__, <keras.layers.core.Activation object at 0x116b653d0>\n",
      "35 : sequential_1_dense_2, <keras.layers.core.Dense object at 0x114fef790>\n",
      "36 : sequential_1_dense_2__activation__, <keras.layers.core.Activation object at 0x116b65410>\n"
     ]
    }
   ],
   "source": [
    "coreml_model  = coremltools.converters.keras.convert(model,\n",
    "                                                    image_input_names='image',\n",
    "                                                    class_labels='labels.txt',\n",
    "                                                    input_names=['image'],  \n",
    "                                                    red_bias=-123.68,\n",
    "                                                    green_bias=-116.78,\n",
    "                                                    blue_bias=-103.94\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model.save('disdatkerasv4.mlmodel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
